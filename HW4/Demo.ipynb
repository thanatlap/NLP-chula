{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRF Tutorial using python-crfsuite\n",
    "\n",
    "In this tutorial, we will try to use CRF to work on part-of-speech (POS) tagging. There are 6 main parts in this tutorial\n",
    "1. Setup and preprocessing\n",
    "2. Designing feature funcions\n",
    "3. Training\n",
    "4. Making predictions\n",
    "5. Evaluation\n",
    "6. Try: Design a more complex model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup and preprocessing\n",
    "\n",
    "In this demo we will use [python-crfsuite](https://github.com/scrapinghub/python-crfsuite)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycrfsuite\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use POS data from [ORCHID corpus](https://www.nectec.or.th/corpus/index.php?league=pm), which is a POS corpus for Thai language.\n",
    "A method used to read the corpus into a list of sentences with (word, POS) pairs have been implemented already. The example usage has shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('การ', 'FIXN'),\n",
       " ('ประชุม', 'VACT'),\n",
       " ('ทาง', 'NCMN'),\n",
       " ('วิชาการ', 'NCMN'),\n",
       " ('<space>', 'PUNC'),\n",
       " ('ครั้ง', 'CFQC'),\n",
       " ('ที่ 1', 'DONM')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data.orchid_corpus import get_sentences\n",
    "train_data = get_sentences('train')\n",
    "test_data = get_sentences('test')\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Designing features functions\n",
    "\n",
    "- __word2features()__: This method returns all feature functions for time step _i_ of an input sequence. So, this method is where all feature functions are defined. From the code, we can define just features from input sequence (word for this example), the library will manage the transition functions ($y_{t-1}$ -> $y_t$) and state functions ($y_t$ -> $X$, with all $X$ features you defined in this method) for you.\n",
    "- __sent2features()__: Loop and call word2features() over the input sequence.\n",
    "- __sent2labels()__: Get the output labels from train/test sequence\n",
    "- __sent2tokens()__: Get words from train/test sequence (used in prediction part just to show the full result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    \n",
    "    features = {\n",
    "        'word': word,\n",
    "        'word.isdigit': word.isdigit(),\n",
    "        'word.length': len(word),\n",
    "    }\n",
    "    \n",
    "    features['BOS'] = (i == 0)  # beginning of sentence\n",
    "    features['EOS'] = (i == len(sent)-1)  # end of sentence\n",
    "    \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for (word, label) in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word for (word, label) in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"  'word.firstLetter': word[0],\\n        'word.lastLetter': word[-1], word.length\": 3,\n",
       " 'BOS': True,\n",
       " 'EOS': False,\n",
       " 'word': 'การ',\n",
       " 'word.isdigit': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_data[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 343 ms, sys: 84.4 ms, total: 427 ms\n",
      "Wall time: 427 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = [sent2features(sent) for sent in train_data]\n",
    "y_train = [sent2labels(sent) for sent in train_data]\n",
    "x_test = [sent2features(sent) for sent in test_data]\n",
    "y_test = [sent2labels(sent) for sent in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training\n",
    "\n",
    "To train a CRF model in python-crfsuite, we have to create a trainer and load training data (pairs of __generated features__ and __labels__) to the trainer first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = pycrfsuite.Trainer(verbose=False)\n",
    "for xseq, yseq in zip(x_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several parameters you can set for the training process. You can list all parameter using this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will use 3 parameters:\n",
    "\n",
    "- __max_iterations__: Define how many times we will let the model learn through training data\n",
    "- __feature.possible_transitions__: Enable the library to create transition feature functions (as we discussed in section 2)\n",
    "- __feature.possible_states__: Enable state feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer.set_params({\n",
    "    'max_iterations': 100,\n",
    "    'feature.possible_transitions': True,\n",
    "    'feature.possible_states': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, call the trainer to train with the specified model path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 44s, sys: 265 ms, total: 5min 45s\n",
      "Wall time: 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_path = 'model/crf_basic.model'\n",
    "trainer.train(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Making predictions\n",
    "\n",
    "When we finished training a model. We can use that model to predict any sequence of words.\n",
    "To do this, create a tagger with path to the saved model. Then, generate features with a sequence we want to predict and send them to _tag_ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x7fe707ad1b38>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<minus> <space> ระบบ การ บันทึก รหัส ไว้ ใน แฟ้มข้อมูล\n",
      "Predicted:  PUNC PUNC NCMN FIXN VACT NCMN XVAE RPRE NCMN\n",
      "Correct:  PUNC PUNC NCMN FIXN VACT NCMN XVAE RPRE NCMN\n"
     ]
    }
   ],
   "source": [
    "example_sent = test_data[20]\n",
    "print(' '.join(sent2tokens(example_sent)))\n",
    "\n",
    "print('Predicted: ', ' '.join(tagger.tag(sent2features(example_sent))))\n",
    "print('Correct: ', ' '.join(sent2labels(example_sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation\n",
    "\n",
    "To measure how good the model can perform, we have to evaluate the model on _test data_. For sequence labeling tasks, we often use __accuracy__ to measure a model's goodness. However, we can analyze further by considering each tag with\n",
    "- __prediction__: How many times the predicted tag _x_ is correctly tagged (it is a tag _x_ in the test data)\n",
    "- __recall__: How many times the real tag _x_ is correctly tagged (the model can answer that it is a tag _x_)\n",
    "\n",
    "The method below, evaluation_report(), is implemented to measure all metrics described and display it in DataFrame. It is ok to just use this method and not going through this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def evaluation_report(y_true, y_pred):\n",
    "    # retrieve all tags in y_true\n",
    "    tag_set = set()\n",
    "    for sent in y_true:\n",
    "        for tag in sent:\n",
    "            tag_set.add(tag)\n",
    "    tag_list = sorted(list(tag_set))\n",
    "    \n",
    "    # count correct points\n",
    "    tag_info = dict()\n",
    "    for tag in tag_list:\n",
    "        tag_info[tag] = {'correct_tagged': 0, 'y_true': 0, 'y_pred': 0}\n",
    "\n",
    "    all_correct = 0\n",
    "    all_count = sum([len(sent) for sent in y_true])\n",
    "    for sent_true, sent_pred in zip(y_true, y_pred):\n",
    "        for tag_true, tag_pred in zip(sent_true, sent_pred):\n",
    "            if tag_true == tag_pred:\n",
    "                tag_info[tag_true]['correct_tagged'] += 1\n",
    "                all_correct += 1\n",
    "            tag_info[tag_true]['y_true'] += 1\n",
    "            tag_info[tag_pred]['y_pred'] += 1\n",
    "    accuracy = (all_correct / all_count) * 100\n",
    "            \n",
    "    # summarize and make evaluation result\n",
    "    eval_list = list()\n",
    "    for tag in tag_list:\n",
    "        eval_result = dict()\n",
    "        eval_result['tag'] = tag\n",
    "        eval_result['correct_count'] = tag_info[tag]['correct_tagged']\n",
    "        precision = (tag_info[tag]['correct_tagged']/tag_info[tag]['y_pred'])*100 if tag_info[tag]['y_pred'] else '-'\n",
    "        recall = (tag_info[tag]['correct_tagged']/tag_info[tag]['y_true'])*100\n",
    "        eval_result['precision'] = precision\n",
    "        eval_result['recall'] = recall\n",
    "        eval_result['f_score'] = (2*precision*recall)/(precision+recall) if (type(precision) is float and recall > 0) else '-'\n",
    "        \n",
    "        eval_list.append(eval_result)\n",
    "\n",
    "    eval_list.append({'tag': 'accuracy=%.2f' % accuracy, 'correct_count': '', 'precision': '', 'recall': '', 'f_score': ''})\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(eval_list)\n",
    "    df = df[['tag', 'precision', 'recall', 'f_score', 'correct_count']]\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on test set (y_pred) and evaluate against the real label (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = [tagger.tag(x_sent) for x_sent in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_score</th>\n",
       "      <th>correct_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADVI</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADVN</td>\n",
       "      <td>69.4611</td>\n",
       "      <td>20.6774</td>\n",
       "      <td>31.8681</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADVP</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADVS</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFQC</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CLTV</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CMTR</td>\n",
       "      <td>13.0435</td>\n",
       "      <td>1.45278</td>\n",
       "      <td>2.61438</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CMTR@PUNC</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNIT</td>\n",
       "      <td>100</td>\n",
       "      <td>3.53261</td>\n",
       "      <td>6.82415</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DCNM</td>\n",
       "      <td>69.9789</td>\n",
       "      <td>72.3497</td>\n",
       "      <td>71.1445</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DDAC</td>\n",
       "      <td>99.7506</td>\n",
       "      <td>68.4932</td>\n",
       "      <td>81.2183</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DDAN</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DDAQ</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DDBQ</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DIAC</td>\n",
       "      <td>100</td>\n",
       "      <td>54.7468</td>\n",
       "      <td>70.7566</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DIAQ</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DIBQ</td>\n",
       "      <td>100</td>\n",
       "      <td>2.71186</td>\n",
       "      <td>5.28053</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DONM</td>\n",
       "      <td>82.5</td>\n",
       "      <td>6.32184</td>\n",
       "      <td>11.7438</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EAFF</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EITT</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FIXN</td>\n",
       "      <td>99.8639</td>\n",
       "      <td>99.5658</td>\n",
       "      <td>99.7146</td>\n",
       "      <td>3669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FIXV</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JCMP</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JCRG</td>\n",
       "      <td>98.4686</td>\n",
       "      <td>92.785</td>\n",
       "      <td>95.5423</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JSBR</td>\n",
       "      <td>67.4906</td>\n",
       "      <td>75.0208</td>\n",
       "      <td>71.0568</td>\n",
       "      <td>1802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NCMN</td>\n",
       "      <td>65.1021</td>\n",
       "      <td>94.3632</td>\n",
       "      <td>77.048</td>\n",
       "      <td>15937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NCNM</td>\n",
       "      <td>90.0826</td>\n",
       "      <td>26.2651</td>\n",
       "      <td>40.6716</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NEG</td>\n",
       "      <td>100</td>\n",
       "      <td>83.5714</td>\n",
       "      <td>91.0506</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NLBL</td>\n",
       "      <td>81.6807</td>\n",
       "      <td>86.4769</td>\n",
       "      <td>84.0104</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NPRP</td>\n",
       "      <td>78.125</td>\n",
       "      <td>8.93921</td>\n",
       "      <td>16.0428</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NTTL</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PDMN</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PNTR</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PPRS</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PREL</td>\n",
       "      <td>92.1071</td>\n",
       "      <td>88.5809</td>\n",
       "      <td>90.3096</td>\n",
       "      <td>1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PUNC</td>\n",
       "      <td>99.9761</td>\n",
       "      <td>97.3147</td>\n",
       "      <td>98.6275</td>\n",
       "      <td>12575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RPRE</td>\n",
       "      <td>79.8522</td>\n",
       "      <td>86.646</td>\n",
       "      <td>83.1105</td>\n",
       "      <td>4756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>VACT</td>\n",
       "      <td>79.7421</td>\n",
       "      <td>77.2187</td>\n",
       "      <td>78.4601</td>\n",
       "      <td>6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>VATT</td>\n",
       "      <td>57.9167</td>\n",
       "      <td>17.3425</td>\n",
       "      <td>26.6923</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>VSTA</td>\n",
       "      <td>86.3093</td>\n",
       "      <td>58.2359</td>\n",
       "      <td>69.5464</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XVAE</td>\n",
       "      <td>90.8098</td>\n",
       "      <td>70.73</td>\n",
       "      <td>79.5219</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XVAM</td>\n",
       "      <td>76.4467</td>\n",
       "      <td>94.0075</td>\n",
       "      <td>84.3225</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XVBM</td>\n",
       "      <td>97.5814</td>\n",
       "      <td>90.8225</td>\n",
       "      <td>94.0807</td>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XVMM</td>\n",
       "      <td>100</td>\n",
       "      <td>59.7101</td>\n",
       "      <td>74.7731</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>accuracy=80.22</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag precision   recall  f_score correct_count\n",
       "0             ADVI         -        0        -             0\n",
       "1             ADVN   69.4611  20.6774  31.8681           232\n",
       "2             ADVP         -        0        -             0\n",
       "3             ADVS         -        0        -             0\n",
       "4             CFQC         -        0        -             0\n",
       "5             CLTV         -        0        -             0\n",
       "6             CMTR   13.0435  1.45278  2.61438             6\n",
       "7        CMTR@PUNC         -        0        -             0\n",
       "8             CNIT       100  3.53261  6.82415            13\n",
       "9             DCNM   69.9789  72.3497  71.1445           662\n",
       "10            DDAC   99.7506  68.4932  81.2183           400\n",
       "11            DDAN         -        0        -             0\n",
       "12            DDAQ         -        0        -             0\n",
       "13            DDBQ         -        0        -             0\n",
       "14            DIAC       100  54.7468  70.7566           173\n",
       "15            DIAQ         -        0        -             0\n",
       "16            DIBQ       100  2.71186  5.28053             8\n",
       "17            DONM      82.5  6.32184  11.7438            33\n",
       "18            EAFF         -        0        -             0\n",
       "19            EITT         -        0        -             0\n",
       "20            FIXN   99.8639  99.5658  99.7146          3669\n",
       "21            FIXV         -        0        -             0\n",
       "22            JCMP         -        0        -             0\n",
       "23            JCRG   98.4686   92.785  95.5423          1929\n",
       "24            JSBR   67.4906  75.0208  71.0568          1802\n",
       "25            NCMN   65.1021  94.3632   77.048         15937\n",
       "26            NCNM   90.0826  26.2651  40.6716           109\n",
       "27             NEG       100  83.5714  91.0506           234\n",
       "28            NLBL   81.6807  86.4769  84.0104           486\n",
       "29            NPRP    78.125  8.93921  16.0428            75\n",
       "30            NTTL         -        0        -             0\n",
       "31            PDMN         -        0        -             0\n",
       "32            PNTR         -        0        -             0\n",
       "33            PPRS         -        0        -             0\n",
       "34            PREL   92.1071  88.5809  90.3096          1342\n",
       "35            PUNC   99.9761  97.3147  98.6275         12575\n",
       "36            RPRE   79.8522   86.646  83.1105          4756\n",
       "37            VACT   79.7421  77.2187  78.4601          6369\n",
       "38            VATT   57.9167  17.3425  26.6923           278\n",
       "39            VSTA   86.3093  58.2359  69.5464          2093\n",
       "40            XVAE   90.8098    70.73  79.5219           998\n",
       "41            XVAM   76.4467  94.0075  84.3225           753\n",
       "42            XVBM   97.5814  90.8225  94.0807          1049\n",
       "43            XVMM       100  59.7101  74.7731           206\n",
       "44  accuracy=80.22                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use pretrained word embedding\n",
    "\n",
    "In this exercise, we will use pretrained word embedding from previous homework as word feature in pycrfsuite. We load pretrained word embedding using pickle. The pretrained weight is a dictionary which map a word to its embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "fp = open('basic_ff_embedding.pt', 'rb')\n",
    "embeddings = pickle.load(fp)\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i, emb):\n",
    "    def add_embedding_features(feat, prefix, query_word):\n",
    "        if query_word in emb:\n",
    "            vec = emb[query_word]\n",
    "        else:\n",
    "            vec = numpy.zeros(32)\n",
    "        \n",
    "        for i in range(vec.shape[0]):\n",
    "            feat[prefix + str(i)] = vec[i]\n",
    "    \n",
    "    features = dict()\n",
    "    word = sent[i][0]\n",
    "    add_embedding_features(features, 'word.embd', word)\n",
    "    features.update({\n",
    "        'word.word' : word,\n",
    "        'word.isdigit': word.isdigit(),\n",
    "        'word.length': len(word),\n",
    "    })\n",
    "    \n",
    "    features['BOS'] = (i == 0)  # beginning of sentence\n",
    "    features['EOS'] = (i == len(sent)-1)  # end of sentence\n",
    "    \n",
    "    return features\n",
    "\n",
    "def sent2features(sent, emb_dict):\n",
    "    return [word2features(sent, i, emb_dict) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for (word, label) in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [word for (word, label) in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.36 s, sys: 452 ms, total: 6.82 s\n",
      "Wall time: 6.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = [sent2features(sent, embeddings) for sent in train_data]\n",
    "y_train = [sent2labels(sent) for sent in train_data]\n",
    "x_test = [sent2features(sent, embeddings) for sent in test_data]\n",
    "y_test = [sent2labels(sent) for sent in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BOS': True,\n",
       " 'EOS': False,\n",
       " 'word.embd0': 0.63079655,\n",
       " 'word.embd1': 0.55423963,\n",
       " 'word.embd10': -0.52982348,\n",
       " 'word.embd11': 0.74475533,\n",
       " 'word.embd12': 0.68278229,\n",
       " 'word.embd13': -0.5775221,\n",
       " 'word.embd14': -0.66996753,\n",
       " 'word.embd15': 0.66535348,\n",
       " 'word.embd16': -0.64394021,\n",
       " 'word.embd17': 0.62942129,\n",
       " 'word.embd18': -0.68831235,\n",
       " 'word.embd19': -0.66224283,\n",
       " 'word.embd2': -0.69944656,\n",
       " 'word.embd20': -0.82274407,\n",
       " 'word.embd21': -0.59909046,\n",
       " 'word.embd22': 0.66668463,\n",
       " 'word.embd23': 0.65602303,\n",
       " 'word.embd24': 0.68236977,\n",
       " 'word.embd25': 0.57738519,\n",
       " 'word.embd26': -0.54963934,\n",
       " 'word.embd27': 0.60753429,\n",
       " 'word.embd28': -0.67751026,\n",
       " 'word.embd29': -0.60196757,\n",
       " 'word.embd3': 0.66754633,\n",
       " 'word.embd30': 0.55823398,\n",
       " 'word.embd31': 0.56031388,\n",
       " 'word.embd4': 0.71997637,\n",
       " 'word.embd5': 0.56522852,\n",
       " 'word.embd6': -0.59826338,\n",
       " 'word.embd7': 0.58731371,\n",
       " 'word.embd8': 0.64380872,\n",
       " 'word.embd9': 0.52099121,\n",
       " 'word.isdigit': False,\n",
       " 'word.length': 3,\n",
       " 'word.word': 'การ'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_data[0], embeddings)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.35 s, sys: 0 ns, total: 6.35 s\n",
      "Wall time: 6.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=True)\n",
    "trainer.set_params({\n",
    "    'max_iterations': 100,\n",
    "    'feature.possible_transitions': True,\n",
    "    'feature.possible_states': True,\n",
    "})\n",
    "\n",
    "for xseq, yseq in zip(x_train, y_train):\n",
    "    trainer.append(xseq, yseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 1\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 709136\n",
      "Seconds required: 55.079\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.000000\n",
      "c2: 1.000000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "***** Iteration #1 *****\n",
      "Loss: 776867.117349\n",
      "Feature norm: 1.000000\n",
      "Error norm: 282725.103522\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 0.000001\n",
      "Seconds required for this iteration: 5.668\n",
      "\n",
      "***** Iteration #2 *****\n",
      "Loss: 741788.669404\n",
      "Feature norm: 0.979262\n",
      "Error norm: 413664.190556\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.896\n",
      "\n",
      "***** Iteration #3 *****\n",
      "Loss: 709224.554318\n",
      "Feature norm: 0.996845\n",
      "Error norm: 263743.801395\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.896\n",
      "\n",
      "***** Iteration #4 *****\n",
      "Loss: 683662.416779\n",
      "Feature norm: 1.143412\n",
      "Error norm: 135359.634561\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.903\n",
      "\n",
      "***** Iteration #5 *****\n",
      "Loss: 652954.799045\n",
      "Feature norm: 1.577672\n",
      "Error norm: 200652.238485\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.887\n",
      "\n",
      "***** Iteration #6 *****\n",
      "Loss: 636532.222452\n",
      "Feature norm: 1.906863\n",
      "Error norm: 134651.985460\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.917\n",
      "\n",
      "***** Iteration #7 *****\n",
      "Loss: 619137.775476\n",
      "Feature norm: 2.300812\n",
      "Error norm: 73885.974634\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.909\n",
      "\n",
      "***** Iteration #8 *****\n",
      "Loss: 605591.598652\n",
      "Feature norm: 2.699326\n",
      "Error norm: 91314.084988\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.906\n",
      "\n",
      "***** Iteration #9 *****\n",
      "Loss: 588258.427815\n",
      "Feature norm: 3.268900\n",
      "Error norm: 101937.356027\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.949\n",
      "\n",
      "***** Iteration #10 *****\n",
      "Loss: 574560.291038\n",
      "Feature norm: 3.899014\n",
      "Error norm: 111204.493560\n",
      "Active features: 709136\n",
      "Line search trials: 2\n",
      "Line search step: 0.440602\n",
      "Seconds required for this iteration: 5.788\n",
      "\n",
      "***** Iteration #11 *****\n",
      "Loss: 559387.953312\n",
      "Feature norm: 4.760191\n",
      "Error norm: 130588.670637\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.857\n",
      "\n",
      "***** Iteration #12 *****\n",
      "Loss: 554164.553119\n",
      "Feature norm: 5.057037\n",
      "Error norm: 105993.062660\n",
      "Active features: 709136\n",
      "Line search trials: 2\n",
      "Line search step: 0.441027\n",
      "Seconds required for this iteration: 5.751\n",
      "\n",
      "***** Iteration #13 *****\n",
      "Loss: 549538.540270\n",
      "Feature norm: 4.991767\n",
      "Error norm: 86851.932828\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.891\n",
      "\n",
      "***** Iteration #14 *****\n",
      "Loss: 535603.477396\n",
      "Feature norm: 5.257655\n",
      "Error norm: 57859.157636\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.928\n",
      "\n",
      "***** Iteration #15 *****\n",
      "Loss: 523413.649244\n",
      "Feature norm: 5.736270\n",
      "Error norm: 70048.351218\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.886\n",
      "\n",
      "***** Iteration #16 *****\n",
      "Loss: 506518.492665\n",
      "Feature norm: 7.553675\n",
      "Error norm: 123076.971742\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.889\n",
      "\n",
      "***** Iteration #17 *****\n",
      "Loss: 497900.687440\n",
      "Feature norm: 9.231402\n",
      "Error norm: 233515.794008\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.912\n",
      "\n",
      "***** Iteration #18 *****\n",
      "Loss: 483321.908810\n",
      "Feature norm: 9.461766\n",
      "Error norm: 74030.676577\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.914\n",
      "\n",
      "***** Iteration #19 *****\n",
      "Loss: 478362.187441\n",
      "Feature norm: 10.085719\n",
      "Error norm: 60981.503493\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.898\n",
      "\n",
      "***** Iteration #20 *****\n",
      "Loss: 470655.170068\n",
      "Feature norm: 12.039613\n",
      "Error norm: 116232.202318\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.908\n",
      "\n",
      "***** Iteration #21 *****\n",
      "Loss: 463998.359384\n",
      "Feature norm: 12.441467\n",
      "Error norm: 61053.585418\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.869\n",
      "\n",
      "***** Iteration #22 *****\n",
      "Loss: 460892.544871\n",
      "Feature norm: 12.535994\n",
      "Error norm: 56579.899389\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.890\n",
      "\n",
      "***** Iteration #23 *****\n",
      "Loss: 447872.019735\n",
      "Feature norm: 13.236209\n",
      "Error norm: 98259.766581\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.857\n",
      "\n",
      "***** Iteration #24 *****\n",
      "Loss: 438945.533943\n",
      "Feature norm: 14.250508\n",
      "Error norm: 73894.088300\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.864\n",
      "\n",
      "***** Iteration #25 *****\n",
      "Loss: 423773.756510\n",
      "Feature norm: 16.911974\n",
      "Error norm: 74657.743447\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.918\n",
      "\n",
      "***** Iteration #26 *****\n",
      "Loss: 414805.730105\n",
      "Feature norm: 17.747343\n",
      "Error norm: 122518.850584\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.888\n",
      "\n",
      "***** Iteration #27 *****\n",
      "Loss: 402941.890694\n",
      "Feature norm: 17.604290\n",
      "Error norm: 76292.952157\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.901\n",
      "\n",
      "***** Iteration #28 *****\n",
      "Loss: 396978.574270\n",
      "Feature norm: 17.786532\n",
      "Error norm: 87447.894803\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.935\n",
      "\n",
      "***** Iteration #29 *****\n",
      "Loss: 390631.938696\n",
      "Feature norm: 17.488927\n",
      "Error norm: 45201.419198\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.906\n",
      "\n",
      "***** Iteration #30 *****\n",
      "Loss: 382645.291665\n",
      "Feature norm: 17.645891\n",
      "Error norm: 63102.190922\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.954\n",
      "\n",
      "***** Iteration #31 *****\n",
      "Loss: 380417.864468\n",
      "Feature norm: 17.534410\n",
      "Error norm: 160614.497255\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.915\n",
      "\n",
      "***** Iteration #32 *****\n",
      "Loss: 374033.597504\n",
      "Feature norm: 17.768096\n",
      "Error norm: 63536.480373\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.911\n",
      "\n",
      "***** Iteration #33 *****\n",
      "Loss: 369638.524084\n",
      "Feature norm: 18.082050\n",
      "Error norm: 50622.339511\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.929\n",
      "\n",
      "***** Iteration #34 *****\n",
      "Loss: 365256.972934\n",
      "Feature norm: 18.521336\n",
      "Error norm: 76400.390422\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.936\n",
      "\n",
      "***** Iteration #35 *****\n",
      "Loss: 358850.772165\n",
      "Feature norm: 19.364302\n",
      "Error norm: 77673.539352\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.902\n",
      "\n",
      "***** Iteration #36 *****\n",
      "Loss: 355119.396498\n",
      "Feature norm: 21.287501\n",
      "Error norm: 129759.018641\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.931\n",
      "\n",
      "***** Iteration #37 *****\n",
      "Loss: 345301.443940\n",
      "Feature norm: 21.831092\n",
      "Error norm: 55045.078409\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.897\n",
      "\n",
      "***** Iteration #38 *****\n",
      "Loss: 340505.130398\n",
      "Feature norm: 22.318765\n",
      "Error norm: 29080.701557\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.898\n",
      "\n",
      "***** Iteration #39 *****\n",
      "Loss: 336138.675079\n",
      "Feature norm: 23.041666\n",
      "Error norm: 34513.754466\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.941\n",
      "\n",
      "***** Iteration #40 *****\n",
      "Loss: 330929.257272\n",
      "Feature norm: 24.257283\n",
      "Error norm: 36175.983294\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.940\n",
      "\n",
      "***** Iteration #41 *****\n",
      "Loss: 329768.467533\n",
      "Feature norm: 24.602592\n",
      "Error norm: 60228.284013\n",
      "Active features: 709136\n",
      "Line search trials: 2\n",
      "Line search step: 0.159027\n",
      "Seconds required for this iteration: 5.885\n",
      "\n",
      "***** Iteration #42 *****\n",
      "Loss: 327311.038487\n",
      "Feature norm: 25.015669\n",
      "Error norm: 37100.838051\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.931\n",
      "\n",
      "***** Iteration #43 *****\n",
      "Loss: 324599.816287\n",
      "Feature norm: 25.266581\n",
      "Error norm: 29219.138371\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.935\n",
      "\n",
      "***** Iteration #44 *****\n",
      "Loss: 320780.374871\n",
      "Feature norm: 25.619695\n",
      "Error norm: 30537.830152\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.929\n",
      "\n",
      "***** Iteration #45 *****\n",
      "Loss: 315802.787139\n",
      "Feature norm: 26.533381\n",
      "Error norm: 46955.988233\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.928\n",
      "\n",
      "***** Iteration #46 *****\n",
      "Loss: 310190.068791\n",
      "Feature norm: 27.967731\n",
      "Error norm: 65050.809375\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.899\n",
      "\n",
      "***** Iteration #47 *****\n",
      "Loss: 304256.754309\n",
      "Feature norm: 28.345086\n",
      "Error norm: 35345.710566\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.794\n",
      "\n",
      "***** Iteration #48 *****\n",
      "Loss: 298142.277519\n",
      "Feature norm: 28.928346\n",
      "Error norm: 58322.984443\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.863\n",
      "\n",
      "***** Iteration #49 *****\n",
      "Loss: 296005.888794\n",
      "Feature norm: 29.287718\n",
      "Error norm: 81380.216316\n",
      "Active features: 709136\n",
      "Line search trials: 2\n",
      "Line search step: 0.419632\n",
      "Seconds required for this iteration: 5.759\n",
      "\n",
      "***** Iteration #50 *****\n",
      "Loss: 293776.448793\n",
      "Feature norm: 29.664852\n",
      "Error norm: 52106.232985\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.903\n",
      "\n",
      "***** Iteration #51 *****\n",
      "Loss: 290689.092898\n",
      "Feature norm: 30.090629\n",
      "Error norm: 32166.785245\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.875\n",
      "\n",
      "***** Iteration #52 *****\n",
      "Loss: 287638.819739\n",
      "Feature norm: 30.604556\n",
      "Error norm: 56165.615047\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.906\n",
      "\n",
      "***** Iteration #53 *****\n",
      "Loss: 284235.294058\n",
      "Feature norm: 31.259670\n",
      "Error norm: 64645.405108\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.896\n",
      "\n",
      "***** Iteration #54 *****\n",
      "Loss: 279065.773159\n",
      "Feature norm: 32.637502\n",
      "Error norm: 42891.139510\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.884\n",
      "\n",
      "***** Iteration #55 *****\n",
      "Loss: 276393.502159\n",
      "Feature norm: 32.928185\n",
      "Error norm: 63165.950093\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.941\n",
      "\n",
      "***** Iteration #56 *****\n",
      "Loss: 273345.398549\n",
      "Feature norm: 33.418607\n",
      "Error norm: 34497.907013\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.876\n",
      "\n",
      "***** Iteration #57 *****\n",
      "Loss: 272337.901954\n",
      "Feature norm: 33.572288\n",
      "Error norm: 33774.911683\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.897\n",
      "\n",
      "***** Iteration #58 *****\n",
      "Loss: 269978.707098\n",
      "Feature norm: 34.202623\n",
      "Error norm: 28129.983135\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.900\n",
      "\n",
      "***** Iteration #59 *****\n",
      "Loss: 265871.622279\n",
      "Feature norm: 35.126932\n",
      "Error norm: 32435.832022\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.893\n",
      "\n",
      "***** Iteration #60 *****\n",
      "Loss: 262242.275561\n",
      "Feature norm: 37.780517\n",
      "Error norm: 96514.870750\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.880\n",
      "\n",
      "***** Iteration #61 *****\n",
      "Loss: 258099.482037\n",
      "Feature norm: 37.612232\n",
      "Error norm: 23109.378221\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.873\n",
      "\n",
      "***** Iteration #62 *****\n",
      "Loss: 256813.963971\n",
      "Feature norm: 37.890100\n",
      "Error norm: 22637.629911\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.919\n",
      "\n",
      "***** Iteration #63 *****\n",
      "Loss: 254340.452926\n",
      "Feature norm: 38.432299\n",
      "Error norm: 27355.735646\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.888\n",
      "\n",
      "***** Iteration #64 *****\n",
      "Loss: 249731.198733\n",
      "Feature norm: 40.693718\n",
      "Error norm: 47080.985482\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.911\n",
      "\n",
      "***** Iteration #65 *****\n",
      "Loss: 245416.271118\n",
      "Feature norm: 41.386418\n",
      "Error norm: 36426.771753\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.942\n",
      "\n",
      "***** Iteration #66 *****\n",
      "Loss: 241947.419133\n",
      "Feature norm: 42.287330\n",
      "Error norm: 28262.038981\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.884\n",
      "\n",
      "***** Iteration #67 *****\n",
      "Loss: 237745.767984\n",
      "Feature norm: 43.112285\n",
      "Error norm: 27338.796939\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.894\n",
      "\n",
      "***** Iteration #68 *****\n",
      "Loss: 236176.417326\n",
      "Feature norm: 43.980100\n",
      "Error norm: 66083.245558\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.894\n",
      "\n",
      "***** Iteration #69 *****\n",
      "Loss: 233922.334036\n",
      "Feature norm: 44.558798\n",
      "Error norm: 32499.478653\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.919\n",
      "\n",
      "***** Iteration #70 *****\n",
      "Loss: 231544.499711\n",
      "Feature norm: 45.456063\n",
      "Error norm: 24358.769347\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.880\n",
      "\n",
      "***** Iteration #71 *****\n",
      "Loss: 229983.745528\n",
      "Feature norm: 46.105256\n",
      "Error norm: 28771.498053\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.901\n",
      "\n",
      "***** Iteration #72 *****\n",
      "Loss: 228776.903382\n",
      "Feature norm: 47.021901\n",
      "Error norm: 38262.003354\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.880\n",
      "\n",
      "***** Iteration #73 *****\n",
      "Loss: 226489.997090\n",
      "Feature norm: 47.784546\n",
      "Error norm: 18533.558912\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.870\n",
      "\n",
      "***** Iteration #74 *****\n",
      "Loss: 225458.284064\n",
      "Feature norm: 47.534579\n",
      "Error norm: 17000.766127\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.890\n",
      "\n",
      "***** Iteration #75 *****\n",
      "Loss: 223347.248636\n",
      "Feature norm: 47.580489\n",
      "Error norm: 16208.559485\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.906\n",
      "\n",
      "***** Iteration #76 *****\n",
      "Loss: 222099.746592\n",
      "Feature norm: 48.292705\n",
      "Error norm: 57788.471627\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.920\n",
      "\n",
      "***** Iteration #77 *****\n",
      "Loss: 220538.313208\n",
      "Feature norm: 48.666254\n",
      "Error norm: 37075.670276\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.875\n",
      "\n",
      "***** Iteration #78 *****\n",
      "Loss: 219760.793013\n",
      "Feature norm: 48.802322\n",
      "Error norm: 24110.654319\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.921\n",
      "\n",
      "***** Iteration #79 *****\n",
      "Loss: 218348.138547\n",
      "Feature norm: 49.298857\n",
      "Error norm: 15580.312421\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.869\n",
      "\n",
      "***** Iteration #80 *****\n",
      "Loss: 216934.000115\n",
      "Feature norm: 49.852830\n",
      "Error norm: 20860.732316\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.896\n",
      "\n",
      "***** Iteration #81 *****\n",
      "Loss: 214872.870152\n",
      "Feature norm: 50.770267\n",
      "Error norm: 34621.072002\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.906\n",
      "\n",
      "***** Iteration #82 *****\n",
      "Loss: 212458.989402\n",
      "Feature norm: 51.678073\n",
      "Error norm: 31603.765754\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.881\n",
      "\n",
      "***** Iteration #83 *****\n",
      "Loss: 209617.417749\n",
      "Feature norm: 52.017936\n",
      "Error norm: 23838.543467\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.918\n",
      "\n",
      "***** Iteration #84 *****\n",
      "Loss: 208187.815671\n",
      "Feature norm: 52.511671\n",
      "Error norm: 54348.939518\n",
      "Active features: 709136\n",
      "Line search trials: 2\n",
      "Line search step: 0.310927\n",
      "Seconds required for this iteration: 5.765\n",
      "\n",
      "***** Iteration #85 *****\n",
      "Loss: 205924.575162\n",
      "Feature norm: 52.829799\n",
      "Error norm: 30724.539043\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.960\n",
      "\n",
      "***** Iteration #86 *****\n",
      "Loss: 204652.478414\n",
      "Feature norm: 53.256145\n",
      "Error norm: 17349.741198\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.913\n",
      "\n",
      "***** Iteration #87 *****\n",
      "Loss: 202952.251617\n",
      "Feature norm: 53.924073\n",
      "Error norm: 18133.356882\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.948\n",
      "\n",
      "***** Iteration #88 *****\n",
      "Loss: 201822.251438\n",
      "Feature norm: 54.446415\n",
      "Error norm: 15435.645700\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.918\n",
      "\n",
      "***** Iteration #89 *****\n",
      "Loss: 200064.762386\n",
      "Feature norm: 55.628475\n",
      "Error norm: 23482.548444\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.926\n",
      "\n",
      "***** Iteration #90 *****\n",
      "Loss: 197892.014612\n",
      "Feature norm: 56.934129\n",
      "Error norm: 21263.616186\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.954\n",
      "\n",
      "***** Iteration #91 *****\n",
      "Loss: 196581.718567\n",
      "Feature norm: 57.171727\n",
      "Error norm: 42024.215055\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.916\n",
      "\n",
      "***** Iteration #92 *****\n",
      "Loss: 194767.217750\n",
      "Feature norm: 57.738963\n",
      "Error norm: 17892.974183\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.953\n",
      "\n",
      "***** Iteration #93 *****\n",
      "Loss: 194147.530539\n",
      "Feature norm: 57.856335\n",
      "Error norm: 18840.314888\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.808\n",
      "\n",
      "***** Iteration #94 *****\n",
      "Loss: 192171.683122\n",
      "Feature norm: 58.708020\n",
      "Error norm: 28243.894553\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.928\n",
      "\n",
      "***** Iteration #95 *****\n",
      "Loss: 190450.573044\n",
      "Feature norm: 60.851844\n",
      "Error norm: 31187.028143\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.933\n",
      "\n",
      "***** Iteration #96 *****\n",
      "Loss: 188955.981047\n",
      "Feature norm: 61.056986\n",
      "Error norm: 16940.137860\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.878\n",
      "\n",
      "***** Iteration #97 *****\n",
      "Loss: 187407.992381\n",
      "Feature norm: 61.581697\n",
      "Error norm: 15612.197806\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.908\n",
      "\n",
      "***** Iteration #98 *****\n",
      "Loss: 186567.398957\n",
      "Feature norm: 62.150214\n",
      "Error norm: 16956.981881\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.876\n",
      "\n",
      "***** Iteration #99 *****\n",
      "Loss: 186268.618149\n",
      "Feature norm: 62.219170\n",
      "Error norm: 41328.095907\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.855\n",
      "\n",
      "***** Iteration #100 *****\n",
      "Loss: 185114.386331\n",
      "Feature norm: 62.638005\n",
      "Error norm: 13669.191909\n",
      "Active features: 709136\n",
      "Line search trials: 1\n",
      "Line search step: 1.000000\n",
      "Seconds required for this iteration: 2.893\n",
      "\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 307.489\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 709136 (709136)\n",
      "Number of active attributes: 15041 (15054)\n",
      "Number of active labels: 47 (47)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.133\n",
      "\n",
      "CPU times: user 6min 2s, sys: 272 ms, total: 6min 2s\n",
      "Wall time: 6min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_path = 'model/crf_neural.model'\n",
    "trainer.train(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.63 s, sys: 4.01 ms, total: 2.64 s\n",
      "Wall time: 2.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_path = 'model/crf_neural.model'\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(model_path)\n",
    "y_pred = [tagger.tag(x_sent) for x_sent in x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f_score</th>\n",
       "      <th>correct_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADVI</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADVN</td>\n",
       "      <td>53.5484</td>\n",
       "      <td>36.9875</td>\n",
       "      <td>43.7533</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADVP</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADVS</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CFQC</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CLTV</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CMTR</td>\n",
       "      <td>48.6239</td>\n",
       "      <td>12.8329</td>\n",
       "      <td>20.3065</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CMTR@PUNC</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNIT</td>\n",
       "      <td>39.3617</td>\n",
       "      <td>20.1087</td>\n",
       "      <td>26.6187</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DCNM</td>\n",
       "      <td>69.715</td>\n",
       "      <td>64.153</td>\n",
       "      <td>66.8184</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DDAC</td>\n",
       "      <td>95.302</td>\n",
       "      <td>72.9452</td>\n",
       "      <td>82.6382</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DDAN</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DDAQ</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DDBQ</td>\n",
       "      <td>20</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.37931</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DIAC</td>\n",
       "      <td>100</td>\n",
       "      <td>57.2785</td>\n",
       "      <td>72.837</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DIAQ</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DIBQ</td>\n",
       "      <td>95.0495</td>\n",
       "      <td>32.5424</td>\n",
       "      <td>48.4848</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DONM</td>\n",
       "      <td>61.7785</td>\n",
       "      <td>75.8621</td>\n",
       "      <td>68.0997</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EAFF</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EITT</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>FIXN</td>\n",
       "      <td>99.4843</td>\n",
       "      <td>99.4573</td>\n",
       "      <td>99.4708</td>\n",
       "      <td>3665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FIXV</td>\n",
       "      <td>85.1064</td>\n",
       "      <td>45.4545</td>\n",
       "      <td>59.2593</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JCMP</td>\n",
       "      <td>85</td>\n",
       "      <td>16.6667</td>\n",
       "      <td>27.8689</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JCRG</td>\n",
       "      <td>97.5745</td>\n",
       "      <td>92.8812</td>\n",
       "      <td>95.17</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JSBR</td>\n",
       "      <td>75.4885</td>\n",
       "      <td>73.98</td>\n",
       "      <td>74.7267</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NCMN</td>\n",
       "      <td>71.6389</td>\n",
       "      <td>93.327</td>\n",
       "      <td>81.0573</td>\n",
       "      <td>15762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NCNM</td>\n",
       "      <td>60.7143</td>\n",
       "      <td>32.7711</td>\n",
       "      <td>42.5665</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NEG</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>94.7368</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NLBL</td>\n",
       "      <td>80.8652</td>\n",
       "      <td>86.4769</td>\n",
       "      <td>83.577</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NPRP</td>\n",
       "      <td>60.7143</td>\n",
       "      <td>10.1311</td>\n",
       "      <td>17.3647</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NTTL</td>\n",
       "      <td>100</td>\n",
       "      <td>18.6047</td>\n",
       "      <td>31.3725</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PDMN</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>PNTR</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PPRS</td>\n",
       "      <td>100</td>\n",
       "      <td>26.7176</td>\n",
       "      <td>42.1687</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>PREL</td>\n",
       "      <td>88.5983</td>\n",
       "      <td>87.1947</td>\n",
       "      <td>87.8909</td>\n",
       "      <td>1321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PUNC</td>\n",
       "      <td>99.9444</td>\n",
       "      <td>97.3611</td>\n",
       "      <td>98.6358</td>\n",
       "      <td>12581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RPRE</td>\n",
       "      <td>89.4934</td>\n",
       "      <td>87.2108</td>\n",
       "      <td>88.3373</td>\n",
       "      <td>4787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>VACT</td>\n",
       "      <td>77.4892</td>\n",
       "      <td>80.2983</td>\n",
       "      <td>78.8687</td>\n",
       "      <td>6623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>VATT</td>\n",
       "      <td>52.0654</td>\n",
       "      <td>37.7417</td>\n",
       "      <td>43.7613</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>VSTA</td>\n",
       "      <td>85.032</td>\n",
       "      <td>62.9104</td>\n",
       "      <td>72.3173</td>\n",
       "      <td>2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XVAE</td>\n",
       "      <td>83.6538</td>\n",
       "      <td>80.1559</td>\n",
       "      <td>81.8675</td>\n",
       "      <td>1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XVAM</td>\n",
       "      <td>85.7814</td>\n",
       "      <td>91.1361</td>\n",
       "      <td>88.3777</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XVBM</td>\n",
       "      <td>96.8722</td>\n",
       "      <td>93.8528</td>\n",
       "      <td>95.3386</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XVMM</td>\n",
       "      <td>96.5217</td>\n",
       "      <td>64.3478</td>\n",
       "      <td>77.2174</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>accuracy=82.55</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag precision    recall  f_score correct_count\n",
       "0             ADVI         -         0        -             0\n",
       "1             ADVN   53.5484   36.9875  43.7533           415\n",
       "2             ADVP         -         0        -             0\n",
       "3             ADVS         -         0        -             0\n",
       "4             CFQC         -         0        -             0\n",
       "5             CLTV         -         0        -             0\n",
       "6             CMTR   48.6239   12.8329  20.3065            53\n",
       "7        CMTR@PUNC         -         0        -             0\n",
       "8             CNIT   39.3617   20.1087  26.6187            74\n",
       "9             DCNM    69.715    64.153  66.8184           587\n",
       "10            DDAC    95.302   72.9452  82.6382           426\n",
       "11            DDAN         -         0        -             0\n",
       "12            DDAQ         -         0        -             0\n",
       "13            DDBQ        20  0.714286  1.37931             1\n",
       "14            DIAC       100   57.2785   72.837           181\n",
       "15            DIAQ         -         0        -             0\n",
       "16            DIBQ   95.0495   32.5424  48.4848            96\n",
       "17            DONM   61.7785   75.8621  68.0997           396\n",
       "18            EAFF         -         0        -             0\n",
       "19            EITT         -         0        -             0\n",
       "20            FIXN   99.4843   99.4573  99.4708          3665\n",
       "21            FIXV   85.1064   45.4545  59.2593            80\n",
       "22            JCMP        85   16.6667  27.8689            17\n",
       "23            JCRG   97.5745   92.8812    95.17          1931\n",
       "24            JSBR   75.4885     73.98  74.7267          1777\n",
       "25            NCMN   71.6389    93.327  81.0573         15762\n",
       "26            NCNM   60.7143   32.7711  42.5665           136\n",
       "27             NEG       100        90  94.7368           252\n",
       "28            NLBL   80.8652   86.4769   83.577           486\n",
       "29            NPRP   60.7143   10.1311  17.3647            85\n",
       "30            NTTL       100   18.6047  31.3725            16\n",
       "31            PDMN         -         0        -             0\n",
       "32            PNTR         -         0        -             0\n",
       "33            PPRS       100   26.7176  42.1687            35\n",
       "34            PREL   88.5983   87.1947  87.8909          1321\n",
       "35            PUNC   99.9444   97.3611  98.6358         12581\n",
       "36            RPRE   89.4934   87.2108  88.3373          4787\n",
       "37            VACT   77.4892   80.2983  78.8687          6623\n",
       "38            VATT   52.0654   37.7417  43.7613           605\n",
       "39            VSTA    85.032   62.9104  72.3173          2261\n",
       "40            XVAE   83.6538   80.1559  81.8675          1131\n",
       "41            XVAM   85.7814   91.1361  88.3777           730\n",
       "42            XVBM   96.8722   93.8528  95.3386          1084\n",
       "43            XVMM   96.5217   64.3478  77.2174           222\n",
       "44  accuracy=82.55                                           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_report(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
